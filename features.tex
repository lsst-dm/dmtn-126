\yusra{As a <type of user>, I want <some feature> so that <some reason>.
Is feature request obvious/self-evident? (Yes/No)
If no, seek use cases.
Can you do it already on lsst-dev? If yes, how? If not, how much work would it be to make it possible?
Can you do it already on LSP? If yes, how? If not, how much work would it be to make it possible?
}

\subsection{All-sky viz}
\yusra{TO DO: Lauren}
 Full sky viz for the area covered per night.  Overlay on full sky viz. Accumulated N of visits on the full sky. Wished for during ops rehearsal.
Where the fields fall in the sky (galaxy, solar system, RA/dec)  (current: hscMap for HSC, doesn't  exist for LSST)
HscMap https://hscmap.mtk.nao.ac.jp/hscMap4

Visualization of all-sky "stuff" (a/k/a statistics, e.g., MAF metrics)
This is the display of quantities that are evaluated across the entire (LSST-observed) sky and are desirable to be able to explore at a range of scales from all-sky down to the finest-grained level at which they are defined.
KB: This becomes more important with LSSTCam and particularly the SV surveys when we start having larger contiguous regions of sky coverage.

Instrument footprint on all sky (or all-sky) images
This could mean both:
display a nominal focal plane footprint at any desired location on the sky, e.g., for use in understanding planned observations; and
display over a coadd the outlines of the single-epoch images used to generate the coadd, or of all the single-epoch images that contain a given source.

BS: 1 (nominal footprint with some catalog of bright sources i.e. "finding chart")
The first of these is implemented already
Second - requires work on the table format of for the data. Moving to an obsCore interface. Functionality overlaps portal and firefly


\subsection{Full Focal Plane Visualization}
\label{sec:features:focal_plane}

The Commissioning, Camera and Data Release Production teams expressed a requirement for visualizing the full focal plane.
Key aspects of this requirement include:

\begin{itemize}

  \item{A ``zoomed out'' overview of the focal plane should be displayed;}
  \item{The user can select and zoom in to particular areas of interest;}
  \item{As the user zooms, data is loaded at progressively higher levels of resolution;}
  \item{Ultimately, at a high enough zoom level, the user can examine the values of individual pixels.}

\end{itemize}

Note that this functionality is only of interest if it is accompanied by the ability to overplot mask planes on the data (\S\ref{sec:features:masks}).

Two tools are currently under development in the LSST ecosystem which may address this requirement: the Camera Image Viewer (\S\ref{sec:existing_tools:camera}) and ExpViewer (\S\ref{sec:existing_tools:misc:expviewer}).
Note, however, that both of these currently rely on compressed image data, so it may not be possible to use them to accurately recover the values of individual pixels.
Furthermore, loading and transmitting full focal plane images is expensive in terms of I/O bandwidth.

Third party packages which can address image visualization at the scale of an LSST focal plane exist.
However, these involve resampling images onto a particular sky tessellation.
For example, the Hierarchical Progressive Survey (HiPS) standard \citep{2017ivoa.spec.0519F} requires that data be resampled on to the HEALPix \citep{gor05}.
This makes it impossible to recover individual LSST pixels from the resampled data.


\subsection{Mark and save positions on images}

\yusra{TO DO: Yusra}

Define regions of interest.

Use Case: Crowd Sourced Image Inspection
Inspect and markup images during commissioning in order to find surfaces that need black paint (analogous to the des-exp-checker)


Showing a particular instance used by DESC for DC2 r2.1i.
Can label image data with ?problems? (e.g. tree rings) that apply at particular positions.
These are then stored to file (either just as text, or maybe a SQLite database), although it's not clear in exactly what representation.
The ?masks? shown are the actually LSST mask, rendered as opaque colour on top of the image.
It's not clear exactly which mask planes are used.
Nice UI.
Clearly a special-purpose tool.
Simple enough that it is appealing to use for appropriate tasks.
?Could use this as a simple GalaxyZoo?.
How would you stand this up for use by the DM team, e.g. for looking at diffim outputs?
Discussed how one might deploy it on e.g. LDF Kubernetes Commons at the T/CAM standup.
And authentication options.
Not appropriate for use for a single user, but could be used for crowd-sourcing visual inspection of data.
This addresses one particular set of use cases, but that set of use cases is highlighted as important in the inputs we've collected.

\subsection{Individual Image Inspection}
\label{sec:ds9}
\yusra{The title of this feature is vague.  Is this the use case supporting maintaining the ability to open images in ds9? Also note that users are most proficient with DS9.}
Independent of all other recommendations, there is still strong interest in the
ability to, outside of any notebook or JupyterLab-like environment, examine
individual raw images in detail using DS9 or some equivalent tool.  Users are
agnostic as to how this tool is provided (i.e. whether it is served through a
web browser or through some kind of terminal forwarding in the vein of xpra).
The principal concerns are that it be able to rapidly load and manipulate pixel
level data and that it be able to operate in a server-client mode so that users
do not have to download terabytes of image data onto their local machines.


\subsection{Compare Images}
\yusra{TO DO: Yusra}
\begin{itemize}
\item{blinking (animation/movie of images}
\item{side-by-side}
\item{Locking two frames by WCS or pixels coordinates}
\item{Locking two frames by scale and limits}
\item{Pan/Zoom}
\end{itemize}

All groups polled requested the ability to directly compare two images, by locking WCS or pixel coordinates, scale and limits, and both blinking and side by side.
After locking users want to be able to pan and zoom while viewing side-by-side or blinking.
Two groups also requested a ``crossfade'' option as ``nice to have'' rather than essential.
Crossfade means that two images are overlaid at the same time, and the user moves a slider to shift the relative weighting of each image.
Ideas's put forth include also include using a movable "curtain" UI element to wipe one image across the other.
\yusra{Whenever photo editing apps that let you compare the before and after of a photographs with a movable curtain, and I always wish they just let me blink.}

Using ds9 on lsst-dev this is possible and easy (for frequent users of ds9).
Using Firefly or matplotlib on Nublado, it may be possible, but it is not easy.

User stories
\begin{itemize}
\item{As a pipelines developer,  I want to be able to blink two locked images so that I can assess the effect of an algorithm modification.}
\item{As a camera team developer,  I want to be able to change the scale limits of two side-by-side images by hand, so that I can see the overscan.}
\end{itemize}


\subsection{Overlay Maps/Masks}
\label{sec:features:masks}
\yusra{Thank you Scott for the draft. TO DO: Gregory edits}

Commissioning, AP, and SST specifically requested the ability to layer images on
top of each other with varying degrees of transparency and multiple colors.
This will be used to overlay the masks (detected, saturated, interpolated, etc.)
from the LSST Science Pipelines as well as maps of known defects on top of
images during visual inspection.  The functionality should be provided through
a realtime UI for use when inspecting an image ``by hand'' and through a
programmatic API for use when inspecting an image in a JupyterLab/notebook
environment.  afwDisplay/ds9 and Firefly both currently support this
functionality.

Overlaying maps onto images (currently use afwDisplay
Toggle individual mask planes and choose colors

SST: Individual mask planes (including: across a full focal plane; for coadds)
"Individual" apparently meaning that one or more mask planes to be displayed could be selected programmatically or by UI, with flexible assignment of colors and transparency.
Princeton says: need full focal plane defect overlays at the summit
mask integration (Firefly does this well)
Obvious nans (e.g. in another color)

Colorized overlays on greyscale images (with tunable alpha)
This refers to the rendering of single-channel image data with a hue or a partially transparent color overlay based on an additional channel (e.g., colorizing a single-channel flux image by the per-pixel variance). Note that mask-overlay display could be treated as an instance of such a capability, but for tracking purposes we'll treat it separately as mask overlays (in paragraph above) which benefit from specialized UIs/APIs for extracting and naming bits from packed bit masks.


\subsection{Callbacks (Run arbitrary code on a pixel or region)}

\yusra{7/12. TO DO:  I'm not sure who is the best person to write this: Gregory John Simon}
Robert says that callbacks are important because they give the use the ability to add any feature to the image viewer. This makes the extant features available in any particular viewer less important.
Yes, If you write it in a way that you can implement arbitrary code and analysis.  Powerful. But I think in JS9 you'd have to write in javascript

Per-source drill down
Select a source/object (in a table, over plotted on an image, in an x-y plot) and be able to link to additional visualizations or data displays related to that source/object/
KB: It would be very nice to be able to click on a source (or collection of sources) in a pixel-level image and have callback to the notebook aspect to run further analysis on those sources. Basically, brushing and linking integration of pixel-level image visualization with the notebook aspect.


\subsubsection{Extensible displays}
% Move elsewhere?
\yusra{TO DO: Simon? John?}
Everything must be scriptable.
We only care that there are APIs for all these things

Because the set of interesting specific visualizations far exceeds what could be provided centrally, make it possible for users to define visualizations, constructed from the lower-level visualization capabilities in the system (or an external library), in a way that makes them straightforward to apply on demand.

\subsection{Snappy User experience}
\yusra{TO DO: Simon}
User experience:
There is a big difference between a viz platform being able to do something and having it be easy or responsive enough to not cause an extra barrier to usage.  A few specific examples of functionality that needs to be gotten right or the tool will suffer from users finding ways to use other tools:
\begin{itemize}

\item{Trivial adjustment of range and zero point of image scaling.
It should be a one click (or hotkey) operation to get a good guess at the scaling range (e.g. z-scale).
Dynamic scaling needs to be achieved through intuitive gestures
Example: When looking at raw frames, the bias has not yet been taken out.  This means each amp needs a different scaling.  When switching between amps, it must be trivial to adjust the scale parameters via the mouse so that a reasonable set of scale parameters can easily be found (ds9 is the standard for this, as far as I know).}
\item{Pan and zoom must be desktop-like
Even a small delay between a drag and the frame panning causes momentary disorientation.
Similarly, if the zoom is not close to continuous and instantaneous, the user must reorient after every change in zoom.
Example: It is common to be at a fairly high zoom level and want to pan around to find a specific type of object or feature.  If the pan takes any fraction of a second, the user needs to figure out where they are so they know where to pan again.  Similarly, one may want to zoom out to find other examples.  If the zoom isn?t smooth, requires cognitive effort to figure out a) when the right zoom has been reached and b) where to pan after the zoom.}
\item{Mouse over values need to update with ultra-low latency
The value of the pixel under the mouse needs to be displayed prominently.
The value must update with ultra-low latency  as the mouse is moved over the image.
Example 1: It is common to want to explore pixel values to get an average by eye of the background.  Just by running the mouse over pixels between objects, it is simple to get a sense of the background value if the mouse over value updates essentially continuously.
Example 2: It is common to want to try to find the ~max pixel value in an object.  Rather than drawing a trace, it is often sufficient to run the mouse over the pixels of the object to look for a gradient and follow it up.  This is much harder to do if it takes significant time to update the mouse over value.
\item{It needs to be simple to match multiple images on either image coordinates or WCS coordinates.}
Given a reference image, snap all other images in other frames to the same image or sky (configurable) coordinates and zoom level with less than three mouse clicks
Once co-registered, pan and zoom should be linked in all panes
This includes the ability to cycle through the frames in the same pane, i.e. ?blinking? through the frames sequentially via a blink selection in a menu option or hotkey.  I.e. not sequentially clicking through a series of tabs or list entries.
Example: There are lots of moving objects in images of any depth.  To find them load three epochs of the same area separated by a few days.  Register all images to the first image to the same sky coordinates.  Stack the images and in one pane and cycle through them automatically with a delay of 0.5 seconds.  Look for points sources that follow a linear trajectory relative to the surrounding stationary point sources.}
\end{itemize}

\subsection{ds9-style "smoothing" (on the fly convolutions)}
\yusra{TO DO: yusra}
Camera team are heavy users of ds9's  "smoothing."
Science Pipelines Team are also heavy users of ds9 smoothing.

\subsection{Mouse over WCS/Pixel}
\yusra{TO DO: Lauren}

Image info. Stats on regions

Position of mouse in WCS and image coords
Pixel value under mouse


\subsection{Dynamic stretch}
\yusra{TO DO: Simon}

Camera team visualizes raw images (still with overscan regions or amp-to-amp offset)
Interactive (and responsive) modification of color stretch parameters

Color scale
Use "Standard" image interactions in a responsive way: scale, stretch, zoom, pan, colormap and basic computation and image analysis capabilities.
There was a general desire for stretch/scale changes to be "fast".
In the meeting we discussed at least three different interpretations of color mapping: rendering of single-channel image data with a color that depends on the flux value (or whatever other variable is represented by the pixel values); rendering of single-channel image data with a hue or a partially transparent color overlay based on an additional channel; generation of color from 3 independent channels. For future purposes we'll treat this use case as referring only to the first of the three; the other two have their own use cases below.
CFC: This needs to include interactive hierarchical capabilities - e.g. display of a full FOV image consisting of 21 science rafts + 4 corner rafts in some definable spatial compression/sampling scheme (e.g. box average, max value, median filter etc..) to make the full FOV image manageable. Interactive feature need to include selecting a specific science or corner raft for more detailed display, followed by selecting a given sensor on a raft for pixel level display and computational (IRAF imexamine like) operations.
Other use cases listed here can be implemented through this one.
BS: 1 (ds9+imexam functionality)


\subsection{Display footprints and heavy footprints}
\yusra{TO DO: Gregory}
Display of LSST data objects with natural on-image interpretations: (Heavy)Footprints, PSF models at a point, PSF variation models or measurements
Footprints should be clickable to facilitate investigation into deblending computations.

Be able to viz intrinsic model (not PSF convolved) (current: matplotlib)
Subtract models from images. Be able to flip from image, model, residuals.   (current: matplotlib)

Pixel-level images with source models subtracted to see visualize residuals with respect to the model
Could be useful for large galaxies, bright stars, evaluating deblending
CFC: Could be useful for stray and scattered light analysis if the source model include ghost images from internal refections of bright sources.

\subsection{Overplot circles/ellipses/footprints}
\yusra{TO DO: Gregory}
Suggested pixel-level image visualization requirements
Ability to overlay sources, along with their model ellipses; must be able to use multiple projections, e.g., instrument, sky; must be able to pan and zoom and adjust color scale quickly; must be able to overlay masks; must be able to see map value and coordinates at mouse location; a "magnifying glass" / zoom-in inset similar to ds9 would be nice to have
CFC: This should be merged with use case 7. (LPG +1)
Overlay sources from other surveys   (current: hscMap for HSC, ????  for LSST)
Overlay source catalog with brushing and linking   (current: Firefly. Though not everyone knows how to use this.)

\subsection{Miscellaneous}
\begin{itemize}
\item{header viewer}
\item{pdf, png, jpeg output}
\item{Viewer in separate window (not just separate tab)}
\end{itemize}

\subsection{Miscellaneous requests not specific to images}
These are catalog visualization requests that augment image display, but aren't specific to displaying images in a technical sense.

\subsubsection{Brushing and linking}
\yusra{TO DO: Gregory}
Across images, histograms, and scatterplots (on the board these pairs of those were called out: image-hist, image-scatter, hist-scatter, but hist-hist, scatter-scatter, and so on also make sense). Support pairwise scatterplots (e.g., displays of the matrix of all x-y plots derivable from a set of N variables).
KB: Bokeh / holoviews / datashader offers much of this capability, for example
CFC: PyVis tools does this.
KB: Brushing and linking between matplotlib plots and python objects in a notebook is definitely important. In addition, it would be really useful to be able to examine an image (e.g., in Firefly), overlay catalog objects, select objects of interest, and then be able to access that selection from a notebook. In other words, I am asking for a linkage between pixel-level images, object catalogs, and the notebook aspect.

\subsubsection{Catalog integration}
\yusra{TO DO: Lauren}
overlay catalogs (markers with additional information beyond coordinates)

Selection of catalogs in the image viewer
Ability to click on a source/pixel in an image and get associated catalog-level data
Plot data about sources from a catalog on top of an image
Hover over things and learn fun metadata facts
e.g. anything from the visitInfo about an image or anything from an associated catalog/database about a source (intentionally left this vague because I'm sure different people want different things)

Turn on and off detection entries in tables, plots based on flags (i.e. with checkboxes)
Applies to any LSST catalog entry with packed Boolean flag fields, including Source, Object, ...
These flag selections are meant to participate in whatever more general brushing and linking environments are provided - e.g., to permit sources/objects with designated flags to be shown or hidden in, say, a color-color plot or in an overlay over an image.

\subsubsection{Flipbooks per source}
\yusra{TO DO: Lauren}
Thumbnails across time (lightcurves), surveys  (current: matplotlib
Quick cutouts of warp, to  look at input images that went into a coadd,
Build mosaics of many images/dataIds on the fly
Collections of thumbnails
Meant to be around a designated set of objects or sources (if sources, this could be a time-dependent selection of apparitions of the same object).

Flip-books per source
Understood to be temporal in nature. Display of image cutout flip-books for selected sources. Automatic definition of default cutout dimensions based on source properties (e.g., smaller for point like sources, larger for extended sources, perhaps including the full parent footprint for deblended sources). Flip books for (raw, calibrated, etc.) flux images; for source models computed for each epoch; for residuals (e.g. from difference imaging vs. templates, or image-to-model residuals, where the model could be per-epoch or time-integrated).
BS: 2 (definitely needed for difference imaging diagnostics)

\subsubsection{Overlay Vector Fields}
\yusra{TO DO: Lauren}
Overlay a vector field, both for the CBP data, and for people doing astrometric matching or looking at distortions.
Vector field plots (e.g., astrometric residuals,PSF moments or other technical information from the EFD)
The scale factor must be adjustable.
KB: matplotlib quiver plots, for example? We definitely need something along those lines for astrometric residuals and PSF characterization
CFC: This seems like something that a visualization would be used to display, but the computation of the vector/quivers is external to the display tool.
