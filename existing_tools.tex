\yusra{Can I imagine writing an \texttt{afwDisplay} for this tool? Do they fulfill any use cases}

\subsection{Firefly}
\yusra{TO DO: Gregory}

Gregory says on Slack:
It's easy to imagine adding a wide variety of new features to Firefly at relatively modest cost, especially, as I mentioned in the meeting last week, ones that mainly involve writing more `afw`-oriented Python interfaces to existing features.
The sticking point we have, and what was behind my question about acceptability to the pipeline developer community last week, is that there are some performance-related issues that are inherent to the client-server architecture, and that would require significant engineering to address (e.g., by moving more of the data and computation to the client, or by doing more cacheing of likely-to-be-requested data). That engineering is not inconceivably difficult - Trey thinks about this kind of stuff all the time - but it may be a disproportionate amount of work compared to the perceived near-term benefit. (edited)
In some cases this is behind the difficulty in addressing what may at first sight appear to be simple UI issues. Merlin asked me, for instance, if we could connect the mouse scroll wheel UI events to the zoom-in and zoom-out actions. Just doing that is (I assume - I'm not a hard-core Javascripter yet) nearly trivial, but it would probably not yield a good UX, because the system is not designed to handle the high rates of actions that would produce.
So Merlin's take on the situation is that very fluid interactive response to zooming - and to rescaling - are more important to him than ``features'' like the mask-plane overlay controls (which he still really likes), and that as a result he's likely to prefer staying with DS9 in preference to starting to use Firefly in his daily work.

(To re-emphasize another earlier point: this is, and should be, totally OK, a choice up to individual developers, and a key motivation to have a ``neutral'' API like `afw.display` in the system. We're not trying to mandate tool use, but to decide where we can get the greatest net benefit to the user community from any additional LSST-funded tool development.) (edited)

We have been gradually making changes to improve the responsiveness of the UI by moving work from the server to the client - for instance, rotations are now done client-side and are really fast - but this is ``big'' work that is probably not realistically doable within the post-descope constraints - and also is not driven strongly by Firefly's other IPAC-side applications. (edited)
From the WG point of view, then, I think we need to understand how this ``fluid response? issue rates in the priorities of the user communities we have. That will then help us assess where best to invest resources. (edited)
(end of essay)


\subsection{Ginga (+Astrowidgets}
\yusra{TO DO: Chris or Yusra}
Things Chris learned at Python in Astronomy, plus a day's worth of experimenting.
Have not yet got \texttt{display\_ginga} working.
Chris has written a quick (~1 hour effort) GUI for interacting with the Ginga display in a notebook; looks pretty slick!
Can display mask planes, by adopting code from (but not integrating with) \texttt{display\_ginga}.
Add regions by clicking on the image; get the results through Python callbacks.
Understands FITS headers; can access them.
Which can actually be populated by metadata provided by the code; it doesn't have to be header.
Not clear what the semantics of this should be.
One could imagine extending afwDisplay with some generic notion of image metadata.
There are handy keybindings.
AstroWidgets acts largely as a wrapper around Ginga.
Chris is working on a way of panning through multiple frames.
Continuing development of AstroWidgets; they claim to now support all of the DS9 region types.

\subsection{JS9}

\yusra{TO DO: Simon}
Eric Mandel actively developing.
Hard to do mask overlays, due to fundamental differences between how DS9 and JS9 handle multiple images in the same app.
Not clear what the multi-client environment is like ? one monolithic server with many clients, or each client spawning its own server?
But note that there may be constraints on this because the browser and the python interpreter would need to have access to the same environment.
As far as we understand at the moment, matching the sort of mask overlay that we currently have in Firefly/DS9 isn't possible.
But that may just be a matter of not fully understanding JS9's capabilities.
The pyjs9 client library wraps a RESTful API exposed by the server.


\subsection{LSST Camera Image Viewer}
\label{sec:existing_tools:camera}

The LSST Camera Team has developed a bespoke image viewing tool to support their activities.
As such, it is primarily aimed at examining raw pixel data recorded from the camera to diagnose hardware issues.
This viewer is being developed by Tony Johnson (SLAC); much of the material below is adapted from his comments.
Given the rapid pace of ongoing development, some of the discussion below may soon (or already) be outdated.

The current version of the Camera Image Viewer is available on the web at \url{https://lsst-camera-dev.slac.stanford.edu/FITSInfo/}.

\subsubsection{Capabilities}

Given its audience and goals, it does not provide facilities which are require for astronomical analysis of the data.
For example, the viewer has no concept of world coordinate system: it simply operates in focal plane pixel coordinates.

Instead, the viewer is designed to provide high-performance interactive display of images corresponding to a full focal plane or subsections thereof.
The development plan prioritizes:

\begin{itemize}

  \item{A web-based interface for selecting and accessing data;}
  \item{Scaling from full focal-plane to individual amplifiers, with real-time panning and zooming;}
  \item{The ability to select, display and analyze regions by hardware device (e.g. particular CCDs, amplifiers, etc.);}
  \item{The ability to perform hardware diagnostic functions on the selected image region;}
  \item{The ability to trigger DM algorithms to run on the selected region;}
  \item{The ability to track and overlay the values of diagnostic measurements with time.}

\end{itemize}

At time of writing, not all of this functionality is currently available.

\subsubsection{Implementation details}

The tool consists of two separate pieces (the ``browser'' and the ``viewer'').
The former is a relatively simple web front end to the Camera image database which enables the user to select data of interest.
The latter is more technically interesting, as it must cope with the technical challenge of making available extremely large quantities of image data to the user in a fast, interactive way.

The viewer is based on the International Image Interoperability Framework\footnote{\url{https://iiif.io}} (IIIF), which defines a standardized API for making image data available on the web at scale.
A primary advantage of this is that existing open-source software is used as the basis of the system.
In particular, the Camera Image Viewer is based on:

\begin{itemize}

  \item{Cantaloupe\footnote{\url{https://cantaloupe-project.github.io}}, a server-side system for reading image data from storage and providing it to clients using IIIF standards;}
  \item{OpenSeadragon\footnote{\url{https://openseadragon.github.io}}, a browser-based Javascript library for receiving and displaying image data.}

\end{itemize}

Both of these tools provide for extensive customizability.
In particular, Cantaloupe has been extended to read data from the FITS files delivered by the camera, while OpenSeadragon is being extended to provide the various user-facing interaction and analysis facilities which are required.

It is worth noting that, although data is stored on the server in FITS format, it is converted to JPEG for transmission to the client.
It is therefore lossily compressed: the original pixel values are not directly available in the image stream.

Also note that --- regardless of the software system used --- loading and displaying full-focal-plane data at a low enough latency to provide a satisfactory interactive experience places a substantial load on the back-end storage system.
This will, of course, scale with the number of clients accessing the system, but one should expect to make a significant investment in hardware underlying the image viewer.

\subsubsection{Application to DM use cases}

The Camera Image Viewer provides an impressively high-performance interactive visualization of the full focal plane in a way that is not easily available through other tooling.
As such, it is of obvious value to the DM Subsystem.

However, the are a number of important limitations:

\begin{itemize}

  \item{The viewer does not have any concept of astronomical coordinate systems or of reprojecting data onto the celestial sphere;}
  \item{The level of analytic functionality currently available is limited, although more is in development;}
  \item{Integration with DM standard display interfaces (\texttt{afw.display}, etc) seems challenging;}
  \item{The current system is tightly coupled to the raw FITS images being produced by the camera: it would require substantial work to access processed data from a Butler repository.}

\end{itemize}

Deploying the system as it now stands at the Data Facility would require some investment in both hardware, to provide the low-latency data access required, and in development, to make it possible to retrieve and display data from Butler repositories rather than just camera raw FITS files.
However, making this investment would provide DM with a critical capability that is not easily available from elsewhere.



\subsection{hscMap}
\label{sec:existing_tools:hscMap}
\yusra{TO DO: Lauren}
hscMap is an image viewer developed at the National Astronomical Observatory of Japan (NAOJ) with a focus on facilitating the exploration of images from the Hyper Suprime-Cam Subaru Strategic Survey (HSC-SSP).
The survey aims at a total areal coverage of $\approx$1400 deg$^2$ of multiband (grizy + 4 narrow-bands) imaging to three depth levels in fields spanning a large fraction of the sky visible from Mauna Kea.
As such, a primary motivating factor was the ability to easily and responsively zoom around and into large areas of the full sky down to the near-pixel level.
A quick tour of the latest release (\url{https://hscmap.mtk.nao.ac.jp/hscMap4/app}) which is currently serving the $\approx$300 deg$^2$ imaging data from the second public data release (PDR2; \url{https://hsc-release.mtk.nao.ac.jp/doc/index.php/survey-2/}) confirms that this goal has been achieved.
Another salient feature that immediately stands out is the ability to combine and view 3-bands in ``true SDSS color'' \citep{2004PASP..116..133L} with adjustable scaling (in addition to the basic RGB coloring).
A current limitation is a lack of detailed (and searchable) documentation providing a deeper understanding of the mechanics and underlying data structures required.
We reached out to the developers for feedback and were directed to what essentially amounts to video (YouTube) demos of selected functionality including: general navigation, overlays including survey specific field names and grids (tracts and patches) as well as common celestial objects, catalog (pre-made in cvs format and containing at least RA and Dec columns) overlays and basic plotting and sub-selecting via a ``rope tool'' on a scatter plot and SQL-style queries of a database, an image cut-out service, uploading local FITS files and cvs catalogs by simple drag and drop, display of HiPS-based tiling data served by the Strasbourg astronomical Data Center, etc., (see \url{http://hscmap.mtk.nao.ac.jp/hscMap4/app/help.html}).
There is also support for integrating hscMap into JupyterLab notebooks (see \url{http://hscmap.mtk.nao.ac.jp/hscMap4/jupyterlab-hscmap/docs})

Despite all these impressive features, we are not currently recommending further investigations into how hscMap could be used as a mainline image viewer for LSST due to a number of (un)known and complicating factors.
These include the need for post processing of the image and catalog data to be served up by a database; the details and resources required are not known to us at this time.
Additionally, it is not clear what the plans are for long-term development of and support for hscMap, potentially limiting the possibility for feature requests.
However, the ability to simply and snappily visualize the whole LSST sky is reason enough to at least keep hscMap in mind when pursuing other toolkits (as recommended in this report).


\subsection{Aladinlite}

Aladinlite is a tool for viewing images on entire-sky scales that allows users
to zoom down to smaller scales defined at the time the images were ingested.
It enables this functionality by storing images in the HiPS (Hierarchical
Progressive Survey) schema [citation to 2015A\&A...578A.114F].  In the HiPS
schema, images are sampled onto iteratively more refined healpixel grids.  These
resamplings are stored on a central server which allows users connecting to that
server to smoothly transition between levels of refinement, down to the
original, finest healpixel sampling.  While this seems to enable much of the
functionality we have recommended, specifically the ability to transition from
full focal plane inspection down to single amplifier inspection, the fact that
the images must be resampled onto a pixel grid that is defined in sky
coordinates means that the raw, sensor-level pixel information is ultimately
lost.  Aladinlite was designed to enable scientists to explore images at the
entire-sky level.  It was not meant to enable engineers to inspect pixel data
from sensors.  While Aladinlite will likely have a role to play in serving LSST
image data to the scientific community, it is unlikely to be helpful during the
process of commissioning the LSST hardware and software.

\subsection{Miscellaneous}
\subsubsection{ExpViewer}
\label{sec:existing_tools:misc:expviewer}

ExpViewer is being developed by a team led by Luiz da Costa in Brazil to provide rapid display of image data received from the camera in the operational era.
A preview version is currently available online at \url{http://expviewer.linea.gov.br}.

ExpViewer is built upon the same International Image Interoperability Framework as the Camera Image viewer (\S\ref{sec:existing_tools:camera}), and also makes use of OpenSeadragon for in-browser display.
However, rather than directly reading data from FITS stored on disk, images are converted to TIFF format when they are ingested by the tool.

ExpViewer and the Camera Image Viewer have a lot in common, but, at time of writing, the Camera Image Viewer provides a wider range of functionality, while ExpViewer provides a simpler and (arguably) more attractive user interface.
The WG understands that discussions are ongoing between the ExpViewer and Camera Image Viewer teams to identify commonalities, avoid duplication, and increase collaboration, but outcomes of this are currently unclear.

Given its ability to work with FITS data (albeit in the camera raw specific form) and its rapid pace of development, the WG suggests that the Camera Image Viewer provides a more attractive tool for potential adoption by DM.


\subsubsection{WorldWideTelescope}
\yusra{TO DO: yusra}
Peter Williams / WorldWideTelescope integrated HSC data with HSC.
Used a tiling scheme named TOAST; and a tool named toasty(?)
Took about 15 minutes to process a tract, but could likely be made faster with effort.
Addresses the whole sky visualization use case.


\yusra{TO DO: format feature vs. tool table (Yusra)}
